{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset related to housing where our task is to predict both the price of a house and its size category (small, medium, large)\n",
    "# based on various features in this example:# Number of bedrooms, Location (0 for rural, 1 for urban), Size in square feet\n",
    "X = np.array([[2, 0, 850], [3, 1, 1200], [4, 1, 1500], [2, 0, 800], [3, 1, 1100],\n",
    " [2, 0, 890],[3, 1, 1300],[4, 1, 1400]])\n",
    "\n",
    "Y = np.array([[200, 0], [250, 1], [300, 2], [180, 0], [240, 1],\n",
    " [220, 0],[270, 1],[290, 2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two targets\n",
    "Y_price = Y[:, 0]\n",
    "Y_size = to_categorical(Y[:, 1], num_classes=3)\n",
    "\n",
    "X_train, X_test, Y_price_train, Y_price_test, Y_size_train, Y_size_test = train_test_split(X, Y_price, Y_size, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup the neural network\n",
    "input_layer = Input(shape=(3,))\n",
    "shared_layers = Dense(64, activation='relu')(input_layer)\n",
    "shared_layers = Dense(32, activation='relu')(shared_layers)\n",
    "\n",
    "price_output = Dense(1, name='price_output')(shared_layers)\n",
    "size_output = Dense(3, activation='softmax', name='size_output')(shared_layers)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[price_output, size_output])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'price_output': 'mean_squared_error', 'size_output': 'categorical_crossentropy'},\n",
    "              metrics={'price_output': ['mae'], 'size_output': ['accuracy']})\n",
    "\n",
    "model.fit(X_train, {'price_output': Y_price_train, 'size_output': Y_size_train},\n",
    "          epochs=50, batch_size=2, verbose=2)  # Set verbose to 0 for simplicity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcP9GIBL2rCG",
    "outputId": "1cae2020-4bc5-42f7-d809-fd06c65eb948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 - 2s - loss: 1697.5551 - price_output_loss: 1618.8091 - size_output_loss: 78.7456 - price_output_mae: 32.7008 - size_output_accuracy: 0.3333 - 2s/epoch - 544ms/step\n",
      "Epoch 2/50\n",
      "3/3 - 0s - loss: 1224.9496 - price_output_loss: 1171.0049 - size_output_loss: 53.9447 - price_output_mae: 28.3151 - size_output_accuracy: 0.3333 - 17ms/epoch - 6ms/step\n",
      "Epoch 3/50\n",
      "3/3 - 0s - loss: 783.3703 - price_output_loss: 733.7957 - size_output_loss: 49.5746 - price_output_mae: 23.3692 - size_output_accuracy: 0.3333 - 19ms/epoch - 6ms/step\n",
      "Epoch 4/50\n",
      "3/3 - 0s - loss: 630.3512 - price_output_loss: 581.1019 - size_output_loss: 49.2492 - price_output_mae: 22.0489 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "3/3 - 0s - loss: 571.7230 - price_output_loss: 532.4390 - size_output_loss: 39.2840 - price_output_mae: 20.9993 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 6/50\n",
      "3/3 - 0s - loss: 282.4107 - price_output_loss: 256.0840 - size_output_loss: 26.3267 - price_output_mae: 12.5952 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 7/50\n",
      "3/3 - 0s - loss: 429.4791 - price_output_loss: 417.3510 - size_output_loss: 12.1282 - price_output_mae: 16.4147 - size_output_accuracy: 0.3333 - 18ms/epoch - 6ms/step\n",
      "Epoch 8/50\n",
      "3/3 - 0s - loss: 188.0285 - price_output_loss: 179.0181 - size_output_loss: 9.0103 - price_output_mae: 11.4879 - size_output_accuracy: 0.1667 - 18ms/epoch - 6ms/step\n",
      "Epoch 9/50\n",
      "3/3 - 0s - loss: 143.5140 - price_output_loss: 137.2306 - size_output_loss: 6.2834 - price_output_mae: 9.4103 - size_output_accuracy: 0.3333 - 19ms/epoch - 6ms/step\n",
      "Epoch 10/50\n",
      "3/3 - 0s - loss: 259.1863 - price_output_loss: 256.9872 - size_output_loss: 2.1991 - price_output_mae: 13.3410 - size_output_accuracy: 0.1667 - 19ms/epoch - 6ms/step\n",
      "Epoch 11/50\n",
      "3/3 - 0s - loss: 239.2415 - price_output_loss: 232.3886 - size_output_loss: 6.8528 - price_output_mae: 13.6176 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 12/50\n",
      "3/3 - 0s - loss: 198.5973 - price_output_loss: 189.4734 - size_output_loss: 9.1239 - price_output_mae: 11.8947 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "3/3 - 0s - loss: 180.2437 - price_output_loss: 174.5123 - size_output_loss: 5.7314 - price_output_mae: 11.8201 - size_output_accuracy: 0.3333 - 20ms/epoch - 7ms/step\n",
      "Epoch 14/50\n",
      "3/3 - 0s - loss: 154.0708 - price_output_loss: 151.5167 - size_output_loss: 2.5541 - price_output_mae: 10.9866 - size_output_accuracy: 0.5000 - 22ms/epoch - 7ms/step\n",
      "Epoch 15/50\n",
      "3/3 - 0s - loss: 176.7052 - price_output_loss: 172.2055 - size_output_loss: 4.4997 - price_output_mae: 10.7315 - size_output_accuracy: 0.3333 - 22ms/epoch - 7ms/step\n",
      "Epoch 16/50\n",
      "3/3 - 0s - loss: 173.0991 - price_output_loss: 170.0068 - size_output_loss: 3.0923 - price_output_mae: 10.6768 - size_output_accuracy: 0.3333 - 24ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "3/3 - 0s - loss: 198.8239 - price_output_loss: 194.6395 - size_output_loss: 4.1843 - price_output_mae: 12.2264 - size_output_accuracy: 0.3333 - 22ms/epoch - 7ms/step\n",
      "Epoch 18/50\n",
      "3/3 - 0s - loss: 202.8849 - price_output_loss: 199.9864 - size_output_loss: 2.8985 - price_output_mae: 12.7228 - size_output_accuracy: 0.3333 - 21ms/epoch - 7ms/step\n",
      "Epoch 19/50\n",
      "3/3 - 0s - loss: 181.1473 - price_output_loss: 178.9319 - size_output_loss: 2.2153 - price_output_mae: 11.5008 - size_output_accuracy: 0.3333 - 18ms/epoch - 6ms/step\n",
      "Epoch 20/50\n",
      "3/3 - 0s - loss: 179.9932 - price_output_loss: 177.8116 - size_output_loss: 2.1816 - price_output_mae: 11.7389 - size_output_accuracy: 0.1667 - 19ms/epoch - 6ms/step\n",
      "Epoch 21/50\n",
      "3/3 - 0s - loss: 164.4279 - price_output_loss: 162.0656 - size_output_loss: 2.3623 - price_output_mae: 10.7047 - size_output_accuracy: 0.3333 - 16ms/epoch - 5ms/step\n",
      "Epoch 22/50\n",
      "3/3 - 0s - loss: 195.2298 - price_output_loss: 192.6709 - size_output_loss: 2.5589 - price_output_mae: 12.3979 - size_output_accuracy: 0.0000e+00 - 13ms/epoch - 4ms/step\n",
      "Epoch 23/50\n",
      "3/3 - 0s - loss: 161.3997 - price_output_loss: 160.0384 - size_output_loss: 1.3613 - price_output_mae: 11.1124 - size_output_accuracy: 0.1667 - 13ms/epoch - 4ms/step\n",
      "Epoch 24/50\n",
      "3/3 - 0s - loss: 205.0831 - price_output_loss: 203.2888 - size_output_loss: 1.7943 - price_output_mae: 11.6753 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 25/50\n",
      "3/3 - 0s - loss: 167.9582 - price_output_loss: 166.4904 - size_output_loss: 1.4678 - price_output_mae: 10.6178 - size_output_accuracy: 0.1667 - 15ms/epoch - 5ms/step\n",
      "Epoch 26/50\n",
      "3/3 - 0s - loss: 156.5345 - price_output_loss: 154.8212 - size_output_loss: 1.7133 - price_output_mae: 11.3150 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 27/50\n",
      "3/3 - 0s - loss: 173.5947 - price_output_loss: 171.8708 - size_output_loss: 1.7239 - price_output_mae: 11.6082 - size_output_accuracy: 0.1667 - 13ms/epoch - 4ms/step\n",
      "Epoch 28/50\n",
      "3/3 - 0s - loss: 159.0728 - price_output_loss: 157.1556 - size_output_loss: 1.9172 - price_output_mae: 11.0792 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 29/50\n",
      "3/3 - 0s - loss: 159.9669 - price_output_loss: 158.3160 - size_output_loss: 1.6509 - price_output_mae: 10.7574 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "3/3 - 0s - loss: 172.1304 - price_output_loss: 170.8305 - size_output_loss: 1.2999 - price_output_mae: 10.3862 - size_output_accuracy: 0.3333 - 15ms/epoch - 5ms/step\n",
      "Epoch 31/50\n",
      "3/3 - 0s - loss: 183.5873 - price_output_loss: 181.0710 - size_output_loss: 2.5163 - price_output_mae: 10.9830 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 32/50\n",
      "3/3 - 0s - loss: 176.7308 - price_output_loss: 175.1470 - size_output_loss: 1.5838 - price_output_mae: 11.0322 - size_output_accuracy: 0.5000 - 13ms/epoch - 4ms/step\n",
      "Epoch 33/50\n",
      "3/3 - 0s - loss: 167.5239 - price_output_loss: 165.4473 - size_output_loss: 2.0766 - price_output_mae: 10.4353 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "3/3 - 0s - loss: 226.3287 - price_output_loss: 223.7059 - size_output_loss: 2.6229 - price_output_mae: 13.7453 - size_output_accuracy: 0.0000e+00 - 15ms/epoch - 5ms/step\n",
      "Epoch 35/50\n",
      "3/3 - 0s - loss: 200.1563 - price_output_loss: 198.1796 - size_output_loss: 1.9767 - price_output_mae: 10.9963 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 36/50\n",
      "3/3 - 0s - loss: 179.9771 - price_output_loss: 177.9812 - size_output_loss: 1.9960 - price_output_mae: 10.8969 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 37/50\n",
      "3/3 - 0s - loss: 154.3857 - price_output_loss: 152.8306 - size_output_loss: 1.5551 - price_output_mae: 10.5054 - size_output_accuracy: 0.3333 - 15ms/epoch - 5ms/step\n",
      "Epoch 38/50\n",
      "3/3 - 0s - loss: 237.4865 - price_output_loss: 234.5917 - size_output_loss: 2.8948 - price_output_mae: 13.1207 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 39/50\n",
      "3/3 - 0s - loss: 181.9814 - price_output_loss: 180.8989 - size_output_loss: 1.0824 - price_output_mae: 10.9472 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 40/50\n",
      "3/3 - 0s - loss: 207.0804 - price_output_loss: 203.0944 - size_output_loss: 3.9860 - price_output_mae: 11.9751 - size_output_accuracy: 0.3333 - 15ms/epoch - 5ms/step\n",
      "Epoch 41/50\n",
      "3/3 - 0s - loss: 147.2538 - price_output_loss: 145.8528 - size_output_loss: 1.4011 - price_output_mae: 10.0017 - size_output_accuracy: 0.5000 - 13ms/epoch - 4ms/step\n",
      "Epoch 42/50\n",
      "3/3 - 0s - loss: 175.4739 - price_output_loss: 173.2121 - size_output_loss: 2.2618 - price_output_mae: 11.7976 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 43/50\n",
      "3/3 - 0s - loss: 188.3156 - price_output_loss: 185.6659 - size_output_loss: 2.6497 - price_output_mae: 11.6091 - size_output_accuracy: 0.1667 - 19ms/epoch - 6ms/step\n",
      "Epoch 44/50\n",
      "3/3 - 0s - loss: 188.7644 - price_output_loss: 186.5670 - size_output_loss: 2.1974 - price_output_mae: 11.0868 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n",
      "Epoch 45/50\n",
      "3/3 - 0s - loss: 180.4869 - price_output_loss: 178.8712 - size_output_loss: 1.6158 - price_output_mae: 11.8660 - size_output_accuracy: 0.1667 - 15ms/epoch - 5ms/step\n",
      "Epoch 46/50\n",
      "3/3 - 0s - loss: 176.2173 - price_output_loss: 174.4907 - size_output_loss: 1.7267 - price_output_mae: 11.7954 - size_output_accuracy: 0.1667 - 13ms/epoch - 4ms/step\n",
      "Epoch 47/50\n",
      "3/3 - 0s - loss: 186.9814 - price_output_loss: 185.5096 - size_output_loss: 1.4719 - price_output_mae: 12.7451 - size_output_accuracy: 0.0000e+00 - 13ms/epoch - 4ms/step\n",
      "Epoch 48/50\n",
      "3/3 - 0s - loss: 214.0664 - price_output_loss: 211.7951 - size_output_loss: 2.2713 - price_output_mae: 13.1441 - size_output_accuracy: 0.3333 - 14ms/epoch - 5ms/step\n",
      "Epoch 49/50\n",
      "3/3 - 0s - loss: 187.5699 - price_output_loss: 185.4072 - size_output_loss: 2.1627 - price_output_mae: 10.8874 - size_output_accuracy: 0.3333 - 15ms/epoch - 5ms/step\n",
      "Epoch 50/50\n",
      "3/3 - 0s - loss: 151.9235 - price_output_loss: 150.0607 - size_output_loss: 1.8628 - price_output_mae: 10.5051 - size_output_accuracy: 0.3333 - 13ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7aa4920c9120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Test Samples - Price Actual vs Predicted and Size Category Actual vs Predicted:\n",
      "Sample 1: Price Actual: 250, Price Predicted: 255.70, Size Actual: 1, Size Predicted: 1\n",
      "Sample 2: Price Actual: 220, Price Predicted: 189.68, Size Actual: 0, Size Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "predictions = model.predict(X_test)\n",
    "price_predictions = predictions[0]\n",
    "size_predictions = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "# Convert one-hot encoding back to size category\n",
    "Y_size_test_actual = np.argmax(Y_size_test, axis=1)\n",
    "\n",
    "print(\"Test Samples - Price Actual vs Predicted and Size Category Actual vs Predicted:\")\n",
    "for i in range(len(price_predictions)):\n",
    "    print(f\"Sample {i+1}: Price Actual: {Y_price_test[i]}, Price Predicted: {price_predictions[i][0]:.2f}, Size Actual: {Y_size_test_actual[i]}, Size Predicted: {size_predictions[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
